emotion_recognition: true
accum_grad: 1
alpha: conv
alpha_conf:
  dropout: 0.1
blank_id: 0
cif_conf:
  addition_encoder: true
  addition_encoder_big: true
  funnel: true
  funnel_skip: true
  noise_threshold: 0.0
  smooth_factor: 1.0
  tail_threshold: 1.0
  threshold: 1.0
cmvn_file: null
dataset_conf:
  batch_conf:
    batch_type: 'static'
    batch_size: 8
  fbank_conf:
    dither: 0.1
    frame_length: 25
    frame_shift: 10
    num_mel_bins: 80
  filter_conf:
    max_length: 30000
    min_length: 10
    token_max_length: 1000000
    token_min_length: 0
  resample_conf:
    resample_rate: 16000
  shuffle: true
  shuffle_conf:
    shuffle_size: 1500
  sort: true
  sort_conf:
    sort_size: 500
  spec_aug: true
  spec_aug_conf:
    max_f: 10
    max_t: 50
    num_f_mask: 2
    num_t_mask: 2
  speed_perturb: true
decoder: transformer
decoder_conf:
  attention_heads: 4
  dropout_rate: 0.1
  linear_units: 2048
  num_blocks: 4
  positional_dropout_rate: 0.1
  self_attention_dropout_rate: 0.1
  src_attention_dropout_rate: 0.1
emotion_recognition: true
encoder: conformer
encoder_conf:
  activation_type: swish
  attention_dropout_rate: 0.1
  attention_heads: 8
  cnn_module_kernel: 15
  cnn_module_norm: layer_norm
  dropout_rate: 0.1
  input_layer: conv2d
  linear_units: 2048
  normalize_before: true
  num_blocks: 1
  output_size: 512
  pos_enc_layer_type: rel_pos
  positional_dropout_rate: 0.1
  selfattention_layer_type: rel_selfattn
  use_cnn_module: true
grad_clip: 4
input_dim: 80
is_json_cmvn: true
joint_conf:
  activation: tanh
  join_dim: 640
  joint_mode: add
  prejoin_linear: true
  skip_connection: true
  tie_embedding: true
joint_type: v3
log_interval: 100
max_epoch: 100
model_conf:
  input_ln: True
  attention_weight: 0.0
  cif_eos: false
  ctc_weight: 0.6
  length_normalized_loss: false
  lsm_weight: 0.1
  predictor_lm: true
  predictor_lm_tie_weight: false
  predictor_lm_weight: 1.0
  predictor_m1: 10000
  predictor_m2: 40000
  predictor_regularisation: true
  quantity_weight: 1.0
optim: adam
optim_conf:
  lr: 0.0002
output_dim: 4
scheduler: warmuplr
scheduler_conf:
  warmup_steps: 20000
vocab_size: 4
# ssl_conf:
#   embedding_dim: 16
#   input_ln: true
#   mask_length: 15
#   mask_prob: 0.01
#   min_masks: 10
#   num_codebooks: 1
#   num_embeddings: 8192
#   num_mel_bins: 80

